{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b7784d",
   "metadata": {},
   "source": [
    "# 03 - Imbalance Handling\n",
    "\n",
    "Objective: compare multiple strategies to handle severe class imbalance without leaking information.\n",
    "\n",
    "Methods:\n",
    "- SMOTE on training data only\n",
    "- Random undersampling (baseline)\n",
    "- Class weights for algorithms that support it\n",
    "\n",
    "We keep validation/test untouched by resampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5820709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from pathlib import Path\n",
    "\n",
    "PROCESSED_DIR = Path('data/processed')\n",
    "X_train = pd.read_csv(PROCESSED_DIR / 'X_train_scaled.csv')\n",
    "y_train = pd.read_csv(PROCESSED_DIR / 'y_train.csv').squeeze()\n",
    "\n",
    "# Class weights (for use in later models)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=[0,1], y=y_train)\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9ae83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect imbalance before resampling\n",
    "class_counts = y_train.value_counts().rename(index={0: 'Non-Fraud', 1: 'Fraud'})\n",
    "display(class_counts)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values, ax=ax)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Training Class Distribution (Imbalanced)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2466a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE on training data only\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Random undersampling for comparison\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train.shape, X_train_smote.shape, X_train_rus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83366e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save resampled datasets for later models\n",
    "X_train_smote.to_csv(PROCESSED_DIR / 'X_train_smote.csv', index=False)\n",
    "y_train_smote.to_csv(PROCESSED_DIR / 'y_train_smote.csv', index=False)\n",
    "X_train_rus.to_csv(PROCESSED_DIR / 'X_train_rus.csv', index=False)\n",
    "y_train_rus.to_csv(PROCESSED_DIR / 'y_train_rus.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f571d",
   "metadata": {},
   "source": [
    "Rationale: SMOTE synthesizes minority class samples to reduce bias, but applying it only to the training set prevents inflating performance on unseen data. Undersampling offers a simpler baseline. Class weights remain available for algorithms that natively support them."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
